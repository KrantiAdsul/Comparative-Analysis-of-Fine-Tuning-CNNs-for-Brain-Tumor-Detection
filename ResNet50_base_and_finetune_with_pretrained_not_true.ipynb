{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce997115",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79737ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from torchvision.datasets import ImageFolder\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc55e38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create ResNet50 baseline without using pretraining weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8add715a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = 'C:/Users/Kranti/Desktop/EE541_project/archive_new/Testing/testing'\n",
    "train_dir = 'C:/Users/Kranti/Desktop/EE541_project/archive_new/Training'\n",
    "val_dir = 'C:/Users/Kranti/Desktop/EE541_project/archive_new/Validation'\n",
    "\n",
    "# Print the number of images in each category for the training set\n",
    "print('Training set:')\n",
    "for class_name in os.listdir(train_dir):\n",
    "    class_dir = os.path.join(train_dir, class_name)\n",
    "    print(class_name + ':', len(os.listdir(class_dir)))\n",
    "\n",
    "# Print the number of images in each category for the validation set\n",
    "print('Validation set:')\n",
    "for class_name in os.listdir(val_dir):\n",
    "    class_dir = os.path.join(val_dir, class_name)\n",
    "    print(class_name + ':', len(os.listdir(class_dir)))\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "# # Create an instance of the VGG16 model\n",
    "# vgg = models.vgg16(pretrained=True)\n",
    "\n",
    "# # Freeze the layers in the VGG16 model\n",
    "# for param in vgg.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "model = torchvision.models.resnet50()\n",
    "\n",
    "# Modify the last linear layer to include dropout\n",
    "model.fc = torch.nn.Sequential(\n",
    "    torch.nn.Linear(in_features=2048, out_features=2048),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(0.8),  # Add dropout layer with dropout rate of 0.5\n",
    "    torch.nn.Linear(in_features=2048, out_features=1),\n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "\n",
    "# Move the model to the GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define the loss function, optimizer, and scheduler\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "# Create transforms for the training and validation data\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Create datasets for the training and validation data\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
    "val_dataset = datasets.ImageFolder(val_dir, transform=val_transforms)\n",
    "\n",
    "# Create data loaders for the training and validation data\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dbcf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to store the training and testing accuracy and loss values\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels.float().unsqueeze(1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        predicted = outputs > 0.5\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.float().unsqueeze(1)).sum().item()\n",
    "    train_loss = running_loss / len(train_dataset)\n",
    "    train_acc = correct / total\n",
    "    \n",
    "    # Evaluate the model on the validation set\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels.float().unsqueeze(1))\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            predicted = outputs > 0.5\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels.float().unsqueeze(1)).sum().item()\n",
    "    val_loss = val_loss / len(val_dataset)\n",
    "    val_acc = correct / total\n",
    "    \n",
    "    # Append the training and validation accuracy and loss values\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{epochs} -- Training Loss: {train_loss:.4f} -- Training Accuracy: {train_acc:.4f} -- Validation Loss: {val_loss:.4f} -- Validation Accuracy: {val_acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9bdf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_dataset = ImageFolder(test_dir, transform=test_transforms)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialize empty lists to store true labels and predicted labels\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels.float().unsqueeze(1))\n",
    "        test_loss += loss.item() * inputs.size(0)\n",
    "        predicted = torch.round(torch.sigmoid(outputs))  # Round the output values\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels.float().unsqueeze(1)).sum().item()\n",
    "\n",
    "        # Append true labels and predicted labels to the respective lists\n",
    "        true_labels.extend(labels.tolist())\n",
    "        predicted_labels.extend(predicted.tolist())\n",
    "\n",
    "test_loss = test_loss / len(test_dataset)\n",
    "test_acc = correct / total\n",
    "print(f'Test Loss: {test_loss:.4f} -- Test Accuracy: {test_acc:.4f}')\n",
    "\n",
    "# Plot the training and validation accuracy curves\n",
    "plt.figure()\n",
    "plt.plot(range(1, epochs+1), train_accuracies, label='Training Accuracy')\n",
    "plt.plot(range(1, epochs+1), val_accuracies, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot the training and validation loss curves\n",
    "plt.figure()\n",
    "plt.plot(range(1, epochs+1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, epochs+1), val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Calculate the confusion matrix\n",
    "confusion_matrix_test = confusion_matrix(true_labels, predicted_labels)\n",
    "print(confusion_matrix_test)\n",
    "\n",
    "# Plot the confusion matrix using Seaborn\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_matrix_test, annot=True, cmap='Blues', fmt='g')\n",
    "plt.title('Confusion Matrix (Test Set)')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e54540",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model, input_size=(3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b4c521",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"C:/Users/Kranti/Desktop/EE541_project/model_state.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4fb78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization before fine-tuning for conv1 layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894c1a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_hook(module, input, output):\n",
    "    num_channels = output.size(1)\n",
    "    num_rows = (num_channels - 1) // 8 + 1\n",
    "\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    for i in range(num_channels):\n",
    "        plt.subplot(num_rows, 8, i + 1)\n",
    "        plt.imshow(output[0, i].detach().cpu().numpy(), cmap=\"gray\")\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# Choose a specific layer and register the hook\n",
    "layer_to_visualize = model.conv1\n",
    "hook = layer_to_visualize.register_forward_hook(visualize_hook)\n",
    "\n",
    "# Run a single image through the model\n",
    "image = torch.randn(1, 3, 224, 224)  # Replace this with a real image from the dataset\n",
    "_ = model(image)\n",
    "\n",
    "hook.remove()  # Remove the hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64ef057",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fine-tuning of above ResNet50 network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24205a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# Set the batch size and number of epochs\n",
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "\n",
    "# Update the dataset paths for finetuning and testing\n",
    "finetuning_dir = 'C:/Users/Kranti/Desktop/EE541_project/archive_new/Testing/finetuning'\n",
    "testing_dir = 'C:/Users/Kranti/Desktop/EE541_project/archive_new/Testing/testing'\n",
    "train_dir = 'C:/Users/Kranti/Desktop/EE541_project/archive_new/Training'\n",
    "val_dir = 'C:/Users/Kranti/Desktop/EE541_project/archive_new/Validation'\n",
    "\n",
    "# Create datasets for the finetuning and testing data\n",
    "finetuning_dataset = datasets.ImageFolder(finetuning_dir, transform=train_transforms)\n",
    "testing_dataset = datasets.ImageFolder(testing_dir, transform=val_transforms)\n",
    "\n",
    "# Create data loaders for the finetuning and testing data\n",
    "finetuning_loader = DataLoader(finetuning_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "testing_loader = DataLoader(testing_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "# Define the learning rates and layers to unfreeze\n",
    "learning_rates = [1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9, 1e-10, 1e-11, 1e-12]\n",
    "layer_unfreeze = list(range(0, -11, -1))\n",
    "\n",
    "# Move the model and loss function to the device\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "# Create lists to store the losses and accuracies\n",
    "train_losses = {i: [] for i in layer_unfreeze}\n",
    "val_losses = {i: [] for i in layer_unfreeze}\n",
    "train_accs = {i: [] for i in layer_unfreeze}\n",
    "val_accs = {i: [] for i in layer_unfreeze}\n",
    "best_val_acc = {i: 0.0 for i in layer_unfreeze}\n",
    "\n",
    "# Create dictionary to store the best validation accuracy for each layer configuration\n",
    "best_val_acc = {i: 0.0 for i in layer_unfreeze}\n",
    "\n",
    "# Create dictionaries to store the true labels and predicted labels for each layer configuration\n",
    "true_labels = {i: [] for i in layer_unfreeze}\n",
    "predicted_labels = {i: [] for i in layer_unfreeze}\n",
    "\n",
    "# Train the model for each learning rate and layer unfreezing combination\n",
    "for i in layer_unfreeze:\n",
    "    # Unfreeze the layers\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    for param in list(model.parameters())[i:]:\n",
    "        param.requires_grad = True\n",
    "\n",
    "    # Set the optimizer for this set of layers\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rates[i])\n",
    "\n",
    "    # Train the model for the specified number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training loop\n",
    "        running_train_loss = 0.0\n",
    "        running_train_corrects = 0\n",
    "        model.train()\n",
    "        for inputs, labels in tqdm(finetuning_loader, desc=f'Train Epoch {i}.{epoch}'):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device).float()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            labels = labels.view(-1, 1)  # Reshape target tensor\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_train_loss += loss.item() * inputs.size(0)\n",
    "            running_train_corrects += torch.sum(torch.round(outputs) == labels)\n",
    "        epoch_train_loss = running_train_loss / len(finetuning_loader.dataset)\n",
    "        epoch_train_acc = running_train_corrects / len(finetuning_loader.dataset)\n",
    "        train_losses[i].append(epoch_train_loss)\n",
    "        train_accs[i].append(epoch_train_acc)\n",
    "\n",
    "        # Validation loop\n",
    "        running_val_loss = 0.0\n",
    "        running_val_corrects = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in tqdm(test_loader, desc=f'Val Epoch {i}.{epoch}'):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device).float()\n",
    "                outputs = model(inputs)\n",
    "                labels = labels.view(-1, 1)  # Reshape target tensor\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_val_loss += loss.item() * inputs.size(0)\n",
    "                running_val_corrects += torch.sum(torch.round(outputs) == labels)\n",
    "                \n",
    "                # Append true labels and predicted labels\n",
    "                true_labels[i] += labels.tolist()\n",
    "                predicted_labels[i] += torch.round(outputs).tolist()\n",
    "\n",
    "            epoch_val_loss = running_val_loss / len(test_loader.dataset)\n",
    "            epoch_val_acc = running_val_corrects / len(test_loader.dataset)\n",
    "            val_losses[i].append(epoch_val_loss)\n",
    "            val_accs[i].append(epoch_val_acc)\n",
    "            print(f'Val Loss: {epoch_val_loss:.4f} Val Acc: {epoch_val_acc:.4f}')\n",
    "    \n",
    "            # Update best validation accuracy\n",
    "            if epoch_val_acc > best_val_acc[i]:\n",
    "                best_val_acc[i] = epoch_val_acc\n",
    "                torch.save(model.state_dict(), f'best_model_{i}.pth')\n",
    "\n",
    "for i in layer_unfreeze:\n",
    "    confusion_matrix_val = confusion_matrix(true_labels[i], predicted_labels[i])\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(confusion_matrix_val, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "    plt.title(f\"Confusion Matrix (Layer Unfreeze: {i})\")\n",
    "    plt.xlabel(\"Predicted Labels\")\n",
    "    plt.ylabel(\"True Labels\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c07fe8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the learning and accuracy curves for each layer configuration\n",
    "for i in layer_unfreeze:\n",
    "    if i < 0:\n",
    "        lr_name = f'lr: {learning_rates[-i-1]}'\n",
    "    else:\n",
    "        lr_name = f'lr: {learning_rates[i]}'\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))\n",
    "    fig.suptitle(f'Layer Unfreeze {i} ({lr_name})')\n",
    "\n",
    "    # Plot the learning curves\n",
    "    ax[0].plot(train_losses[i], label='Train')\n",
    "    ax[0].plot(val_losses[i], label='Validation')\n",
    "    ax[0].set_xlabel('Epoch')\n",
    "    ax[0].set_ylabel('Loss')\n",
    "    ax[0].legend()\n",
    "    ax[0].grid(True)\n",
    "\n",
    "    # Plot the accuracy curves\n",
    "    ax[1].plot(train_accs[i], label='Train')\n",
    "    ax[1].plot(val_accs[i], label='Validation')\n",
    "    ax[1].set_xlabel('Epoch')\n",
    "    ax[1].set_ylabel('Accuracy')\n",
    "    ax[1].legend()\n",
    "    ax[1].grid(True)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6811b0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization after fine-tuning for conv1 layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5407b6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_hook(module, input, output):\n",
    "    num_channels = output.size(1)\n",
    "    num_rows = (num_channels - 1) // 8 + 1\n",
    "\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    for i in range(num_channels):\n",
    "        plt.subplot(num_rows, 8, i + 1)\n",
    "        plt.imshow(output[0, i].detach().cpu().numpy(), cmap=\"gray\")\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "# Choose a specific layer and register the hook\n",
    "layer_to_visualize = model.conv1\n",
    "hook = layer_to_visualize.register_forward_hook(visualize_hook)\n",
    "\n",
    "# Run a single image through the model\n",
    "image = torch.randn(1, 3, 224, 224)  # Replace this with a real image from the dataset\n",
    "_ = model(image)\n",
    "\n",
    "hook.remove()  # Remove the hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8496f387",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
